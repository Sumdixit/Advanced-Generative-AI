{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "snBYHptMnyJb",
   "metadata": {
    "id": "snBYHptMnyJb"
   },
   "source": [
    "# **Demo: LangChain Memory**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Dld3JlxbT53P",
   "metadata": {
    "id": "Dld3JlxbT53P"
   },
   "source": [
    "#__Description:__\n",
    "In this activity, you will learn how to use different types of memory in LangChain. Each type of memory serves a unique purpose and can be used in different scenarios depending on the requirements of your conversation model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cVXoe4RUn3O8",
   "metadata": {
    "id": "cVXoe4RUn3O8"
   },
   "source": [
    "# **Steps to Perform:**\n",
    "\n",
    "1. Import the Necessary Modules\n",
    "2. Initialize the Chat Model\n",
    "3. Define ConversationBufferMemory\n",
    "4. Define ConversationBufferWindowMemory with a Window Size of 1\n",
    "5. Define ConversationTokenBufferMemory with a Maximum Token Limit of 30\n",
    "6. Define ConversationSummaryBufferMemory with a Maximum Token Limit of 100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eyRI2cM0UL1J",
   "metadata": {
    "id": "eyRI2cM0UL1J"
   },
   "source": [
    "# **Step 1: Import the Necessary Modules**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85e3c5a",
   "metadata": {
    "id": "f85e3c5a"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory, ConversationBufferWindowMemory, ConversationTokenBufferMemory, ConversationSummaryBufferMemory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96c4bc3-0839-49a6-b53a-ab07fc1666dc",
   "metadata": {},
   "source": [
    "`added ST`\n",
    "\n",
    "\n",
    "Buffer → Remembers everything.\n",
    "\n",
    "BufferWindow → Remembers only the last few turns.\n",
    "\n",
    "TokenBuffer → Remembers until a token limit is reached.\n",
    "\n",
    "SummaryBuffer → Remembers old stuff as a summary + recent details.\n",
    "### Quick Comparison of LangChain Memory Types\n",
    "\n",
    "| Memory Type       | What it Keeps                  | Good For                           |\n",
    "|-------------------|--------------------------------|------------------------------------|\n",
    "| **Buffer**        | Full history                  | Short conversations                |\n",
    "| **BufferWindow**  | Last *k* turns                 | Medium convos, cost control        |\n",
    "| **TokenBuffer**   | Last *n* tokens                | Token-efficient context            |\n",
    "| **SummaryBuffer** | Summarized old + full recent   | Very long convos, continuity       |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cFIuxtHkUTIc",
   "metadata": {
    "id": "cFIuxtHkUTIc"
   },
   "source": [
    "# **Step 2: Initialize the Chat Model**\n",
    "\n",
    "\n",
    "*   Initialize the chat model with a temperature of 0.0.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab3e43e",
   "metadata": {
    "id": "3ab3e43e"
   },
   "outputs": [],
   "source": [
    "\n",
    "llm = ChatOpenAI(temperature=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1H_MPaTsUZdr",
   "metadata": {
    "id": "1H_MPaTsUZdr"
   },
   "source": [
    "# **Step 3: Define ConversationBufferMemory**\n",
    "\n",
    "\n",
    "*   Utilize it in a ConversationChain for making predictions and printing the memory buffer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32525373",
   "metadata": {
    "id": "32525373",
    "outputId": "94f91c9d-0550-4f10-d677-c75aa61498c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hello, my name is Alex\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hello, my name is Alex\n",
      "AI: Hello Alex! It's nice to meet you. How can I assist you today?\n",
      "Human: What is 2+2?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hello, my name is Alex\n",
      "AI: Hello Alex! It's nice to meet you. How can I assist you today?\n",
      "Human: What is 2+2?\n",
      "AI: 2+2 is equal to 4.\n",
      "Human: What is my name?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Human: Hello, my name is Alex\n",
      "AI: Hello Alex! It's nice to meet you. How can I assist you today?\n",
      "Human: What is 2+2?\n",
      "AI: 2+2 is equal to 4.\n",
      "Human: What is my name?\n",
      "AI: Your name is Alex.\n"
     ]
    }
   ],
   "source": [
    "memory = ConversationBufferMemory()\n",
    "conversation = ConversationChain(llm=llm, memory = memory, verbose=True)\n",
    "conversation.predict(input=\"Hello, my name is Alex\")\n",
    "conversation.predict(input=\"What is 2+2?\")\n",
    "conversation.predict(input=\"What is my name?\")\n",
    "print(memory.buffer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fHKrpuvIUfny",
   "metadata": {
    "id": "fHKrpuvIUfny"
   },
   "source": [
    "# **Step 4: Define ConversationBufferWindowMemory with a Window Size of 1**\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22fef2b-1cf4-42d8-85b6-333b65974684",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c406c55",
   "metadata": {
    "id": "3c406c55",
    "outputId": "dd708430-a4a1-4a89-d140-f144c40bcd9d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': \"Human: I'm good, thanks\\nAI: Great to hear!\"}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory = ConversationBufferWindowMemory(k=1)\n",
    "memory.save_context({\"input\": \"Hello\"}, {\"output\": \"How are you?\"})\n",
    "memory.save_context({\"input\": \"I'm good, thanks\"}, {\"output\": \"Great to hear!\"})\n",
    "memory.load_memory_variables({})  #load_memory_variables → retrieves the current memory content."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07cTgW8BUtvk",
   "metadata": {
    "id": "07cTgW8BUtvk"
   },
   "source": [
    "# **Step 5: Define ConversationTokenBufferMemory with a Maximum Token Limit of 30**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf9a0bf-4891-4f06-b7bf-b51a935ff481",
   "metadata": {},
   "source": [
    "#ADDED ST\n",
    "\n",
    "\n",
    "Text: \"Machine learning is fun!\"\n",
    "\n",
    "\n",
    "Tokens: [\"Machine\", \" learning\", \" is\", \" fun\", \"!\"]  → 5 tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01a67ba",
   "metadata": {
    "id": "e01a67ba",
    "outputId": "7342f887-ab75-4eb9-9b6d-730085ab98fb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: AI Assistants are what?\\nAI: Impressive!'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory = ConversationTokenBufferMemory(llm=llm, max_token_limit=30)\n",
    "memory.save_context({\"input\": \"Machine Learning is what?!\"}, {\"output\": \"Incredible!\"})\n",
    "memory.save_context({\"input\": \"Neural Networks are what?\"}, {\"output\": \"Fascinating!\"})\n",
    "memory.save_context({\"input\": \"AI Assistants are what?\"}, {\"output\": \"Impressive!\"})\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "N5B6Y6g9U15e",
   "metadata": {
    "id": "N5B6Y6g9U15e"
   },
   "source": [
    "# **Step 6: Define ConversationSummaryBufferMemory with a Maximum Token Limit of 100**\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713bc684",
   "metadata": {
    "id": "713bc684",
    "outputId": "e781ab8b-d02d-4f2e-b04b-d14a75a82917"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': \"System: The human greets the AI and asks what it is doing. The AI responds that it is working. The human then asks about the AI's agenda for the day.\\nAI: There is a meeting at 10am with your design team. You will need your sketch designs ready. 11am-2pm have time to work on your LangChain project which will go smoothly because Langchain is such a powerful tool. At 2pm, lunch at the sushi restaurant with a client who is flying in to meet you to understand the latest in AI. Be sure to bring your tablet to show the latest LLM demo.\"}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schedule = \"There is a meeting at 10am with your design team. \\\n",
    "You will need your sketch designs ready. \\\n",
    "11am-2pm have time to work on your LangChain \\\n",
    "project which will go smoothly because Langchain is such a powerful tool. \\\n",
    "At 2pm, lunch at the sushi restaurant with a client who is flying \\\n",
    "in to meet you to understand the latest in AI. \\\n",
    "Be sure to bring your tablet to show the latest LLM demo.\"\n",
    "memory = ConversationSummaryBufferMemory(llm=llm, max_token_limit=100)\n",
    "memory.save_context({\"input\": \"Hi\"}, {\"output\": \"Hello\"})\n",
    "memory.save_context({\"input\": \"What's up?\"}, {\"output\": \"Not much, just working\"})\n",
    "memory.save_context({\"input\": \"What is on the agenda today?\"}, {\"output\": f\"{schedule}\"})\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "uxHfpP_fVBNB",
   "metadata": {
    "id": "uxHfpP_fVBNB"
   },
   "source": [
    "# **Conclusion**\n",
    "You learned how to use different types of memory in LangChain and how to implement and use ConversationBufferMemory, ConversationBufferWindowMemory, ConversationTokenBufferMemory, and ConversationSummaryBufferMemory. You’ve also understood how ConversationSummaryBufferMemory can handle larger pieces of information, such as a daily schedule. This knowledge will help you effectively utilize LangChain’s memory capabilities in your projects.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db224b5-bfba-434e-bf99-f4fb57d924f2",
   "metadata": {
    "id": "4db224b5-bfba-434e-bf99-f4fb57d924f2"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
